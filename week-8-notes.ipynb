{"metadata":{"kernelspec":{"name":"ir","display_name":"R","language":"R"},"language_info":{"name":"R","codemirror_mode":"r","pygments_lexer":"r","mimetype":"text/x-r-source","file_extension":".r","version":"4.0.5"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"library(keras)\nlibrary(tidyverse)","metadata":{"_uuid":"051d70d956493feee0c6d64651c6a088724dca2a","_execution_state":"idle","execution":{"iopub.status.busy":"2022-03-07T08:25:14.907166Z","iopub.execute_input":"2022-03-07T08:25:14.909743Z","iopub.status.idle":"2022-03-07T08:25:14.936956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train_images and train_labels form the training set, the data that the model will\nlearn from. The model will then be tested on the test set, test_images and test_labels","metadata":{}},{"cell_type":"code","source":"mnist <- dataset_mnist()\ntrain_images <- mnist$train$x\ntrain_labels <- mnist$train$y\ntest_images <- mnist$test$x\ntest_labels <- mnist$test$y","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:27:23.987679Z","iopub.execute_input":"2022-03-01T16:27:23.989653Z","iopub.status.idle":"2022-03-01T16:27:25.153898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"we’ll feed the neural network the training data,\ntrain_images and train_labels","metadata":{}},{"cell_type":"code","source":"network <- keras_model_sequential() %>%\n layer_dense(units = 512, activation = \"relu\", input_shape = c(28 * 28))  %>%\n layer_dense(units = 10, activation = 'softmax')","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:06:26.067523Z","iopub.execute_input":"2022-03-01T16:06:26.069643Z","iopub.status.idle":"2022-03-01T16:06:26.118733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The compilation step","metadata":{}},{"cell_type":"code","source":"network %>% compile(\noptimizer = \"rmsprop\",\nloss = \"categorical_crossentropy\",\nmetrics = c(\"accuracy\")\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:07:51.353183Z","iopub.execute_input":"2022-03-01T16:07:51.355414Z","iopub.status.idle":"2022-03-01T16:07:51.389221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Previous array has shape (60000, 28, 28) with value in [0, 255], we transform it into shape (60000, 28, 28) with values between 0 and 1","metadata":{}},{"cell_type":"code","source":"train_images <- array_reshape(train_images, c(60000, 28 * 28))\ntrain_images <- train_images / 255\ntest_images <- array_reshape(test_images, c(10000, 28 * 28))\ntest_images <- test_images / 255","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:26:41.789981Z","iopub.execute_input":"2022-03-01T16:26:41.791705Z","iopub.status.idle":"2022-03-01T16:26:43.914422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels <- to_categorical(train_labels)\ntest_labels <- to_categorical(test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:12:10.119016Z","iopub.execute_input":"2022-03-01T16:12:10.1212Z","iopub.status.idle":"2022-03-01T16:12:10.162193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"train the model","metadata":{}},{"cell_type":"code","source":"network %>% fit(train_images, train_labels, epochs = 5, batch_size = 128)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:12:12.308714Z","iopub.execute_input":"2022-03-01T16:12:12.3106Z","iopub.status.idle":"2022-03-01T16:12:27.884072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metrics <- network %>% evaluate(test_images, test_labels)\nmetrics","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:12:46.848724Z","iopub.execute_input":"2022-03-01T16:12:46.850903Z","iopub.status.idle":"2022-03-01T16:12:47.674049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1D tensor\nx <- c(12, 3, 6, 14, 10)\n \n# matrics(2D tensors)\nx <- matrix(rep(0, 3*5), nrow = 3, ncol = 5)\nx\n\n# 3d tensors\nx <- array(rep(0, 2*3*2), dim = c(2,3,2))\ndim(x)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:15:44.05297Z","iopub.execute_input":"2022-03-01T16:15:44.054859Z","iopub.status.idle":"2022-03-01T16:15:44.090402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"A tensor is defined by three key attributes:\n\n- Number of axes\n- Shape: an integer vector that describes how many dimensions the tensor has\nalong each axis.\n- Data typeThe following selects digits #10 to #99 and puts them in an array of shape (90, 28,\n28):","metadata":{}},{"cell_type":"markdown","source":"The following selects digits #10 to #99 and puts them in an array of shape (90, 28,\n28):","metadata":{}},{"cell_type":"code","source":"my_slice <- train_images[10:99,,]\ndim(my_slice)","metadata":{"execution":{"iopub.status.busy":"2022-03-01T16:27:28.552347Z","iopub.execute_input":"2022-03-01T16:27:28.554179Z","iopub.status.idle":"2022-03-01T16:27:28.574766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"deep-learning models don’t process an entire dataset at once; rather, they\nbreak the data into small batches. Concretely, here’s one batch of our MNIST digits, with\nbatch size of 128","metadata":{}},{"cell_type":"code","source":"batch <- train_images[1:128,,]\nbatch <- train_images[129:256,,]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.1 Working with text data","metadata":{}},{"cell_type":"markdown","source":"Vectorizing text can be done in mutiple ways\n\n- Segment text into words, and transform each word into a vector.\n- Segment text into characters, and transform each character into a vector.\n- Extract N-grams of words or characters, and transform each N-gram into a vector.","metadata":{}},{"cell_type":"code","source":"## one hot encoding\nsamples <- c(\"The cat sat on the mat.\", \"The dog ate my homework.\")\ntoken_index <- list()\nfor (sample in samples){\n    for (word in strsplit(sample, \" \")[[1]]){\n        if (!word %in% names(token_index)){\n            token_index[[word]] <- length(token_index) + 2\n        }\n    }\n}\nmax_length <- 10\nresults <- array(0, dim = c(length(samples),max_length,max(as.integer(token_index))))\n\nfor (i in 1:length(samples)) {\nsample <- samples[[i]]\nwords <- head(strsplit(sample, \" \")[[1]], n = max_length)\nfor (j in 1:length(words)) {\nindex <- token_index[[words[[j]]]]\nresults[[i, j, index]] <- 1\n}\n}\n    \n             ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using keras for word-level one-hot encoding\n\nlibrary(keras)\n# Creates a tokenizer, configured to only take into account the 1,000 most common words\nsamples <- c(\"The cat sat on the mat.\", \"The dog ate my homework.\")\ntokenizer <- text_tokenizer(num_words = 1000) %>% \n    fit_text_tokenizer(samples)\n\nsequences <- texts_to_sequence(tokenizer, samples)\none_hot_results <- texts_to_matrix(tokenizer, samples, mode = \"binary\")\nword_index <- tokenizer$word_index\ncat(\"Found\", length(word_index), \"unique tokens\\n.\")\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using word embeddings","metadata":{}},{"cell_type":"markdown","source":"## LEARNING WORD EMBEDDINGS WITH AN EMBEDDING LAYER","metadata":{}},{"cell_type":"code","source":"# input_dim: the number of possible tokens\nembbedding_layer <- layer_embedding(input_dim = 1000, output_dim=64)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_features <- 10000\nmaxlen <- 20\nimdb <- dataset_imdb(num_word = max_features)\nc(c(x_train, y_train), c(x_test, y_test)) %<-% imdb\n\nx_train <- pad_sequences(x_train, maxlen = maxlen)\nx_test <- pad_sequences(x_test, maxlen = maxlen)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T08:25:57.124601Z","iopub.execute_input":"2022-03-07T08:25:57.126269Z","iopub.status.idle":"2022-03-07T08:26:08.665968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\n    layer_embedding(input_dim = 10000, output_dim=8, input_length=maxlen) %>%\nlayer_flatten()\nlayer_dense(unit=1, activation = 'sigmoid')\n\nmodel %>% compile(\noptimizer = 'rmsprop',\nloss = \"binary_crossentropy\",\nmetrics = c(\"acc\")\n)\n\nsummary(model)\nhistory <- model %>% \n    fit(x_train, y_train, epochs = 10, batch_size = 32, validation_split = 0.2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using pretrained word embedding\nimdb_dir <- \"~/Downloads/aclImdb\"\ntrain_dir <- file.path(imdb_dir, \"train\")\nlabels <- c()\ntexts <- c()\nfor (label_type in c(\"neg\", \"pos\")) {\nlabel <- switch(label_type, neg = 0, pos = 1)\ndir_name <- file.path(train_dir, label_type)\nfor (fname in list.files(dir_name, pattern = glob2rx(\"*.txt\"),\nfull.names = TRUE)) {\ntexts <- c(texts, readChar(fname, file.info(fname)$size))\nlabels <- c(labels, label)\n}\n}\nTOKENIZING","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxlen <- 100\ntraining_samples <- 200\nvalidation_samples <- 10000\nmax_words <- 10000\ntokenizer <- text_tokenizer(num_words = max_words) %>%\nfit_text_tokenizer(texts)\nsequences <- texts_to_sequences(tokenizer, texts)\nword_index = tokenizer$word_index\ncat(\"Found\", length(word_index), \"unique tokens.\\n\")\ndata <- pad_sequences(sequences, maxlen = maxlen)\nlabels <- as.array(labels)\ncat(\"Shape of data tensor:\", dim(data), \"\\n\")\ncat('Shape of label tensor:', dim(labels), \"\\n\")\nindices <- sample(1:nrow(data))\ntraining_indices <- indices[1:training_samples]\nvalidation_indices <- indices[(training_samples + 1):\n(training_samples + validation_samples)]\nx_train <- data[training_indices,]\ny_train <- labels[training_indices]\nx_val <- data[validation_indices,]\ny_val <- labels[validation_indices]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using glove embedding \n1. download from nlp.stanford.edu/projects/glove","metadata":{}},{"cell_type":"code","source":"# using glove embedding \nglove_dir = '~/Downloads/glove.6B'\nlines <- readLines(file.path(glove_dir, \"glove.6B.100d.txt\"))\nembeddings_index <- new.env(hash = TRUE, parent = emptyenv())\nfor (i in 1:length(lines)) {\nline <- lines[[i]]\nvalues <- strsplit(line, \" \")[[1]]\nword <- values[[1]]\nembeddings_index[[word]] <- as.double(values[-1])\n}\ncat(\"Found\", length(embeddings_index), \"word vectors.\\n\")\n\n# prepare the glove word-embedding matrix\nembedding_dim <- 100\nembedding_matrix <- array(0, c(max_words, embedding_dim))\nfor (word in names(word_index)) {\nindex <- word_index[[word]]\nif (index < max_words) {\nembedding_vector <- embeddings_index[[word]]\nif (!is.null(embedding_vector))\nembedding_matrix[index+1,] <- embedding_vector\n}\n}","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# understanding recurrent neural networks\nIt loops over timesteps, and at each timestep, it considers its current state at t and the input at t.\n","metadata":{}},{"cell_type":"code","source":"state_t <- 0\nfor (input_t in input_sequence) {\noutput_t <- activation(dot(W, input_t) + dot(U, state_t) + b)\nstate_t <- output_t\n}\n\noutput_t <- tanh(as.numeric((W %*% input_t) + (U %*% state_t) + b))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# layer_simple_rnn can be run in two different modes: it can return either the full sequences of successive outputs for each timestep (a\n# 3D tensor of shape (batch_size, timesteps, output_features)) or only the last output for each input sequence\nlibrary(keras)\nmodel <- keras_model_sequential() %>%\nlayer_embedding(input_dim = 10000, output_dim = 32) %>%\nlayer_simple_rnn(units = 32)\n> summary(model)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# we can stack several recurrent layers one after the other\nmodel <- keras_model_sequential() %>%\nlayer_embedding(input_dim = 10000, output_dim = 32) %>%\nlayer_simple_rnn(units = 32, return_sequences = TRUE) %>%\nlayer_simple_rnn(units = 32, return_sequences = TRUE) %>%\nlayer_simple_rnn(units = 32, return_sequences = TRUE) %>%\nlayer_simple_rnn(units = 32)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# IMDB movie-review-classification problem","metadata":{}},{"cell_type":"code","source":"library(keras)\nmax_features <- 10000\nmaxlen <- 500\nbatch_size <- 32\ncat(\"Loading data...\\n\")\nimdb <- dataset_imdb(num_words = max_features)\nc(c(input_train, y_train), c(input_test, y_test)) %<-% imdb\ncat(length(input_train), \"train sequences\\n\")\ncat(length(input_test), \"test sequences\")\ncat(\"Pad sequences (samples x time)\\n\")\ninput_train <- pad_sequences(input_train, maxlen = maxlen)\ninput_test <- pad_sequences(input_test, maxlen = maxlen)\ncat(\"input_train shape:\", dim(input_train), \"\\n\")\ncat(\"input_test shape:\", dim(input_test), \"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:49:58.104912Z","iopub.execute_input":"2022-03-07T15:49:58.106439Z","iopub.status.idle":"2022-03-07T15:50:16.636163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Training the model with embedding and simple RNN layers\nmodel <- keras_model_sequential() %>%\nlayer_embedding(input_dim = max_features, output_dim = 32) %>%\nlayer_simple_rnn(units = 32) %>%\nlayer_dense(units = 1, activation = \"sigmoid\")\nmodel %>% compile(\noptimizer = \"rmsprop\",\nloss = \"binary_crossentropy\",\nmetrics = c(\"acc\")\n)\nhistory <- model %>% fit(\ninput_train, y_train,\nepochs = 10,\nbatch_size = 128,\nvalidation_split = 0.2\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:50:32.933283Z","iopub.execute_input":"2022-03-07T15:50:32.934764Z","iopub.status.idle":"2022-03-07T15:54:12.600742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot(history)","metadata":{"execution":{"iopub.status.busy":"2022-03-07T15:54:12.603732Z","iopub.execute_input":"2022-03-07T15:54:12.605505Z","iopub.status.idle":"2022-03-07T15:54:13.528936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM in Keras","metadata":{}},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\nlayer_embedding(input_dim = max_features, output_dim = 32) %>%\nlayer_lstm(units = 32) %>%\nlayer_dense(units = 1, activation = \"sigmoid\")\nmodel %>% compile(\noptimizer = \"rmsprop\",\nloss = \"binary_crossentropy\",\nmetrics = c(\"acc\")\n)\nhistory <- model %>% fit(\ninput_train, y_train,\nepochs = 10,\nbatch_size = 128,\nvalidation_split = 0.2\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # 6.3 Advanced use of recurrent neural networks","metadata":{}},{"cell_type":"markdown","source":"## Gated recurrent unit layer","metadata":{}},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\nlayer_gru(units = 32, input_shape = list(NULL, dim(data)[[-1]])) %>%\nlayer_dense(units = 1)\nmodel %>% compile(","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# using dropout","metadata":{}},{"cell_type":"code","source":"\nmodel <- keras_model_sequential() %>%\nlayer_gru(units = 32, dropout = 0.2, recurrent_dropout = 0.2,\ninput_shape = list(NULL, dim(data)[[-1]])) %>%\nlayer_dense(units = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stacking recurrent layers","metadata":{}},{"cell_type":"code","source":"# Stacking recurrent layers\nmodel <- keras_model_sequential() %>%\nlayer_gru(units = 32,\ndropout = 0.1,\nrecurrent_dropout = 0.5,\nreturn_sequences = TRUE,\ninput_shape = list(NULL, dim(data)[[-1]])) %>%\nlayer_gru(units = 64, activation = \"relu\",\ndropout = 0.1,\nrecurrent_dropout = 0.5) %>%\nlayer_dense(units = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Using bidirectional RNNs","metadata":{}},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\nlayer_embedding(input_dim = max_features, output_dim = 32) %>%\nbidirectional(\nlayer_lstm(units = 32)\n) %>%\nlayer_dense(units = 1, activation = \"sigmoid\")\n\n# bidirectional GRU\nmodel <- keras_model_sequential() %>%\nbidirectional(\nlayer_gru(units = 32), input_shape = list(NULL, dim(data)[[-1]])\n) %>%\nlayer_dense(units = 1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6.4 Sequence processing with convnets","metadata":{}},{"cell_type":"code","source":"model <- keras_model_sequential() %>%\nlayer_conv_1d(filters = 32, kernel_size = 5, activation = \"relu\",\ninput_shape = list(NULL, dim(data)[[-1]])) %>%\nlayer_max_pooling_1d(pool_size = 3) %>%\nlayer_conv_1d(filters = 32, kernel_size = 5, activation = \"relu\") %>%\nlayer_max_pooling_1d(pool_size = 3) %>%\nlayer_conv_1d(filters = 32, kernel_size = 5, activation = \"relu\") %>%\nlayer_global_max_pooling_1d() %>%\nlayer_dense(units = 1)\n","metadata":{},"execution_count":null,"outputs":[]}]}